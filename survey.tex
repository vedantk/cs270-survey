\documentclass{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumerate}
\usepackage[a4paper]{geometry}

\title{Spectral Graph Sparsification}
\author{Vedant Kumar}

\begin{document}
\maketitle

\newcommand \textlcsc[1]{\textsc{\MakeLowercase{#1}}}

\section*{Abstract}

Graph sparsification algorithms find sparse approximations of graphs. In
this paper we survey major results in spectral sparsification, a special
case in which important structural and algebraic properties of graphs are
preserved. We explain and provide intuition for a key result: that every
graph has a spectral sparsifier with $O(|V|\log|V|)$ edges w.h.p, and that
such a sparsifier can be found in $\tilde{O}(|E|)$ time. We finish by
discussing some applications of spectral sparsification, such as computing
electrical flows and finding minimum $s$-$t$ cuts in nearly-linear time.

\section{Introduction}

Sparse graphs have a comparable number of edges and vertices, up to a
poly-logarathmic factor ($|E| \in \tilde{O}(|V|)$). In contrast, dense
graphs (such as the complete graph) permit a quadratic number of edges ($|E|
\in O(|V|^2)$). If the number of vertices is fixed, many graph algorithms
run significantly faster and with lower space requirements on sparse inputs.
Moreover, each edge in a sparse graph tends to contribute `more' to the
overall structure of the graph.  Working with sparse graphs can save time,
save space, and provide insight into the nature of a graph: this makes graph
sparsification interesting.

In order to assess the quality of a sparsification algorithm, we need a way
to measure similarity between a graph and its sparse approximation. Section
2 discusses two different measures of graph similarity --
\textit{cut-similarity} and \textit{spectral-similarity} -- both of which
led to the discovery of important sparsification algorithms. Section 3
contains a detailed exposition of a fast spectral sparsification algorithm
based on an edge-sampling scheme.  Section 4 mentions some applications of
spectral sparsification, and Section 5 reprises some of the key ideas
presented in this survey.

\section{Measuring Similarity}

We're trying to define `approximate'.

\subsection{Definitions}

For our purposes, a graph is a tuple of vertices, undirected edges, and edge
weights $G = (V, E, w)$. 

\subsection{Cut similarity}

Def. cut-similar, discuss.

Describe Benczúr-Karger, state thm 1.

\subsection{Spectral similarity}

Def. spectrally-similar, discuss.

Describe Spielman-Teng, go up to thm 4.

\section{Sparsification with Sampling}

Cover the effective-resistances paper.

\section{Applications}

\section{Overview}

\section*{References}

\begin{enumerate}[1.]
    \item Achlioptas, D., Mcsherry, F. Fast computation of low-rank matrix
approximations. 2 (2007), 9.

    \item Batson, J.D., Spielman, D.A., Srivastava, N.  Twice-Ramanujan
sparsifiers. 6 (2012), 1704 –1721.

    \item Benczúr, A.A., Karger, D.R.  Approximating s-t minimum cuts in O(n 2
) time. In (1996), 47–55.

    \item Chandra, A.K., Raghavan, P., Ruzzo, W.L., Smolensky, R., Tiwari, P.
The electrical resistance of a graph captures its commute and cover times. In
(1989), ACM, New York, NY, USA, 574–586.

    \item Cheeger, J. A lower bound for smallest eigenvalue of Laplacian. In
(1970), Princeton University Press, 195–199.
\end{enumerate}

\end{document}
